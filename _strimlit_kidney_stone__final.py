# -*- coding: utf-8 -*-
""""Strimlit: Kidney Stone" final

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ALgmPXyFCtqQBt8tvdTjQ9wY-W3LunZr
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import seaborn as sns
import pandas as pd 
import matplotlib.pyplot as plt
from sklearn.ensemble import GradientBoostingClassifier
from xgboost import XGBClassifier
from lightgbm import LGBMClassifier
from sklearn.ensemble import ExtraTreesClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import RepeatedStratifiedKFold
from sklearn.metrics import roc_auc_score
from lightgbm import LGBMClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import cross_val_score

from sklearn.model_selection import cross_validate, GridSearchCV, train_test_split, StratifiedKFold


import warnings
warnings.filterwarnings("ignore")
# %matplotlib inline

"""# DOWNLOAD DATASET"""

train = pd.read_csv('train.csv')
test = pd.read_csv('test.csv')
origin = pd.read_csv('kindey_stone_urine_analysis.csv')



sample_submission = pd.read_csv('sample_submission.csv')

train.drop(columns='id', inplace=True)

"""# EDA"""

train.target.value_counts()

df = pd.concat([train, origin], axis=0)

from sklearn.utils import shuffle

df = shuffle(df)

def missing_values(df):
    return pd.DataFrame({
        'feature': df.columns,
        'missing_values': df.isna().sum(),
    }).set_index('feature').sort_values(by='missing_values', ascending=False)

display(missing_values(df).T)

"""# PYCARET"""

pip install pycaret

from pycaret.classification import *

# Commented out IPython magic to ensure Python compatibility.
# %time 
setup(data = df, 
      target = 'target')

compare_models(sort='AUC',n_select = 5)

df.describe().T

"""we can see high std of osmo, urea features."""

# Create multiple plots with a given size
fig = plt.figure(figsize=(15,12))

features = df.columns[0:-1]

# Create a countplot to evaluate the distribution
for i, feature in enumerate(features):
    ax = plt.subplot(3, 3, i+1)
    sns.histplot(x=feature, data=train, label="Playground_Train", color='#800080', ax=ax, alpha=0.5, kde=True)
    sns.histplot(x=feature, data=origin, label="Playground_Train", color='#800080', ax=ax, alpha=0.5, kde=True)
    sns.histplot(x=feature, data=test, label="Test", color='#006b3c', ax=ax, alpha=0.5, kde=True)
    ax.set_xlabel(feature, fontsize=12)

# Create the legend
fig.legend(labels=['Playground_Train', 'Original_Train', 'Test'], loc='upper center', bbox_to_anchor=(0.5, 0.96), fontsize=12, ncol=3)

# Adjust the spacing between the subplots and the legend
fig.subplots_adjust(top=0.90, bottom=0.05, left=0.10, right=0.95, hspace=0.45, wspace=0.45)

plt.show()

import seaborn as sbs
import matplotlib.pyplot as plt

features = ['gravity', 'ph', 'osmo', 'cond', 'urea', 'calc', 'target']
corr = df[features].corr(method = 'spearman')
fig = plt.figure(figsize=(10,5))
ax = fig.add_subplot(111)
cax = ax.matshow(corr,cmap='coolwarm', vmin=-1, vmax=1)
fig.colorbar(cax)
ticks = np.arange(0,len(corr.columns),1)
ax.set_xticks(ticks)
plt.xticks(rotation=90)
ax.set_yticks(ticks)
ax.set_xticklabels(df[features].columns)
ax.set_yticklabels(df[features].columns)
plt.show()

"""- Correlatin matrix suggests that "ph" has a negative relationship with target and "osmo" and "gravity" seems to have a positive relationship.
- osmo has high corellation with urea.
"""

(df.corr()['target']*100).sort_values(ascending=False)

from statsmodels.stats.outliers_influence import variance_inflation_factor

vif = pd.DataFrame()
vif['VIF'] = [variance_inflation_factor(df[features].values, i) for i in range(df[features].shape[1])]
vif['variable'] = df[features].columns

vif.sort_values(by='VIF', ascending=False)

"""# FEATURE ENGINERING """

#def add_features(df):
    #df['osmo_without_urea'] = df['osmo'] - df['urea']   
    #df["gravity/ph"] = df["gravity"] / df["ph"]
    #df["osmo/cond"] = df["osmo"] / df["cond"]
    #df["gravity*ph"] = df["gravity"] * df["ph"]
    #df["gravity*osmo"] = df["gravity"] * df["osmo"]
    #df["osmo*urea"] = df["osmo"] * df["urea"]
    #df["cond_urea_ph"] = df["cond"] * df["urea"] / df["ph"]
    #df["ph*osmo"] = df["ph"] * df["osmo"]
    #df["cond*calc"] = df["cond"] * df["calc"]
    #df["gravity/calc"] = df["gravity"] / df["calc"]

    #return df

#df = add_features(df)

df.describe().T

# encode the target variable
from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()

le.fit(df['target'])

Y = pd.Series(data = le.transform(df['target']))

"""# BASELINE MODEL"""

classifiers = [
    ('Random Forest', RandomForestClassifier(n_estimators=150, random_state=42)),
    ('LR', LogisticRegression(random_state=42)),
    ('Gradient Boosting', GradientBoostingClassifier(n_estimators=150, learning_rate=0.1, max_depth=3, random_state=42)),
    ('XGBoost', XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)),
    ('lightgbm', LGBMClassifier(random_state=42))
]

X = df.drop(["target"], axis =1)


for name, classifier in classifiers:
    clf = classifier
    # Perform cross-validation with 10-folds
    cv_scores = cross_val_score(clf, X, Y, cv=10, scoring='roc_auc') 
    # Print the cross-validation scores
    print(f"Average cross-validation score for {name}:", np.mean(cv_scores))
    print(f"Std cross-validation score for {name}:", np.std(cv_scores))
    print("-"*20)

"""# OPTUNA"""

!pip install optuna

import optuna

def objective(trial):
    max_depth = trial.suggest_int('max_depth', 1, 100)
    n_estimators = trial.suggest_int('n_estimators', 10, 500)
    min_samples_split = trial.suggest_int('min_samples_split', 2, 10)
    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 10)
    
    classifier = RandomForestClassifier(max_depth=max_depth, n_estimators=n_estimators, 
                                         min_samples_split=min_samples_split, 
                                         min_samples_leaf=min_samples_leaf, 
                                         n_jobs=2)
    
    #cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)
    score = cross_val_score(classifier, X, Y, cv=5, scoring="roc_auc")
    
    mean_score = score.mean()
    
    return mean_score

study = optuna.create_study(direction='maximize')
study.optimize(objective, timeout=50) # temps de la recherche 600 secondes, soit 10 minutes

model = RandomForestClassifier(max_depth=study.best_params['max_depth'], 
                               n_estimators=study.best_params['n_estimators'], 
                               min_samples_split=study.best_params['min_samples_split'], 
                               min_samples_leaf=study.best_params['min_samples_leaf'], 
                               n_jobs=2)

model.fit(X, Y)

test.drop(columns='id', inplace=True)

pred = model.predict_proba(test)[:,1]

submission= pd.DataFrame({
    'id' : sample_submission['id'],
    'target' : pred
})

submission.to_csv('submission.csv', index= False)
pd.read_csv('submission.csv', index_col=0)

"""# Приложение streamlit"""

!pip install joblib

pip install shap

import joblib

joblib_file = "model.pkl" 
joblib.dump(model, joblib_file)
model = joblib.load("model.pkl")

!pip install -q streamlit

import joblib
import streamlit as st
import pandas as pd
import base64
import pickle
from PIL import Image
from urllib.request import urlopen
import shap

image = Image.open(urlopen('https://f.stolichki.ru/s/media/articles/131b46e7ed0d3f49207a796922803e59.jpg'))

st.title('# Kidney Stone Prediction based on Urine Analysis')

st.image(image, use_column_width=True)

st.markdown("""
      The six physical characteristics of the urine are: (1) specific gravity, the density of the urine relative to water; (2) pH, the negative logarithm of the hydrogen ion; (3) osmolarity (mOsm), a unit used in biology and medicine but not in
      physical chemistry. Osmolarity is proportional to the concentration of
      molecules in solution; (4) conductivity (mMho milliMho). One Mho is one
      reciprocal Ohm. Conductivity is proportional to the concentration of charged
      ions in solution; (5) urea concentration in millimoles per litre; and (6) calcium
      concentration (CALC) in millimolesllitre.
      The data is obtained from 'Physical Characteristics of Urines With and Without Crystals',a chapter from Springer Series in Statistics.
      ***
""")


st.sidebar.header("Specify input parameters")

def user_input_features():
  GRAVITY = st.sidebar.slider('GRAVITY', float(X.gravity.min()), float(X.gravity.max()), float(X.gravity.mean()))
  PH = st.sidebar.slider('PH', float(X.ph.min()), float(X.ph.max()), float(X.ph.mean()))
  OSMO = st.sidebar.slider('OSMO', float(X.osmo.min()), float(X.osmo.max()), float(X.osmo.mean()))
  COND = st.sidebar.slider('COND', float(X.cond.min()), float(X.cond.max()), float(X.cond.mean()))
  UREA = st.sidebar.slider('UREA', float(X.urea.min()), float(X.urea.max()), float(X.urea.mean()))
  CALC = st.sidebar.slider('CALC', float(X.calc.min()), float(X.calc.max()), float(X.calc.mean()))

  data = {'gravity': GRAVITY,
          'ph': PH,
          'osmo': OSMO,
          'cond': COND, 
          'urea': UREA,
          'calc': CALC}

  features = pd.DataFrame(data, index=[0])
  return features

df = user_input_features()

# add new features 
#df = add_features(df)


st.header('Specified input parameters')
st.write(df)
st.write('---')

model = joblib.load("model.pkl")

prediction = model.predict(df)


st.header('Prediction of Kidney Stone')
st.write(prediction)
if prediction == 0:
  st.write("You don't have kidney stones")
else:
  st.write("You have kidney stones. See a doctor")

st.write('---')


explainer = shap.TreeExplainer(model)
shap_values = explainer.shap_values(X)

st.header('Feature Importance')
plt.title('Feature importance based on SHAP values')
shap.summary_plot(shap_values, X)
st.pyplot(bbox_inches='tight')
st.write('---')

!npm install localtunnel

!streamlit run /content/streamlit_app.py &>/content/logs.txt &

!npx localtunnel --port 8501